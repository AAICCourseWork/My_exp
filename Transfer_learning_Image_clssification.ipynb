{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Copy of Transfer Learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0zs3TflcAEr",
        "colab_type": "text"
      },
      "source": [
        "<pre>\n",
        "1. Download all the data in this folder https://drive.google.com/open?id=1Z4TyI7FcFVEx8qdl4jO9qxvxaqLSqoEu. it contains two file both images and labels. The label file list the images and their categories in the following format:\n",
        "            <b>path/to/the/image.tif,category</b>\n",
        "            \n",
        "    where the categories are numbered 0 to 15, in the following order:\n",
        "\n",
        "    <b>0 letter\n",
        "    1 form\n",
        "    2 email\n",
        "    3 handwritten\n",
        "    4 advertisement\n",
        "    5 scientific report\n",
        "    6 scientific publication\n",
        "    7 specification\n",
        "    8 file folder\n",
        "    9 news article\n",
        "    10 budget\n",
        "    11 invoice\n",
        "    12 presentation\n",
        "    13 questionnaire\n",
        "    14 resume\n",
        "    15 memo</b>\n",
        "    \n",
        "2. On this image data, you have to train 3 types of models as given below. You have to split the data into Train and Validation data.\n",
        "\n",
        "3. Try not to load all the images into memory, use the gernarators that we have given the reference notebooks to load the batch of images only during the train data.\n",
        "or you can use this method also\n",
        "<a href='https://medium.com/@vijayabhaskar96/tutorial-on-keras-imagedatagenerator-with-flow-from-dataframe-8bd5776e45c1'>https://medium.com/@vijayabhaskar96/tutorial-on-keras-imagedatagenerator-with-flow-from-dataframe-8bd5776e45c1</a>\n",
        "\n",
        "<a href='https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c'>https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c</a>\n",
        "\n",
        "\n",
        "4. You are free to choose Learning rate, optimizer, loss function, image augmentation, any hyperparameters. but you have to use the same architechture what we are asking below. \n",
        "\n",
        "5. Use tensorboard for every model and analyse your gradients. (you need to upload the screenshots for each model for evaluation)\n",
        "\n",
        "Note: fit_genarator() method will have problems with the tensorboard histograms, try to debug it, if you could not do use histgrams=0 i.e don't include histograms, check the documentation of tensorboard for more information. \n",
        "\n",
        "6. You can check about Transfer Learning in this link - <a href='https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html'>https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html</a>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amKbfojfcAE-",
        "colab_type": "text"
      },
      "source": [
        "### Model-3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9AULF-PcAFC",
        "colab_type": "text"
      },
      "source": [
        "<pre>\n",
        "1. Use same network as Model-2 '<b>INPUT --> VGG-16 without Top layers(FC) --> 2 Conv Layers identical to FC --> Output Layer</b>' and train only Last 6 Layers of VGG-16 network, 2 Conv layers identical to FC layers, 1 output layer.\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi5pH4TAeKmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjRtNDhmjcV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive3 = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yenlm2CsjgeE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "link='https://drive.google.com/open?id=1Z4TyI7FcFVEx8qdl4jO9qxvxaqLSqoEu'\n",
        "fluff, id = link.split('=')\n",
        "downloaded = drive3.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('rvl-cdip.rar') \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96YVuzrYl_k5",
        "colab_type": "code",
        "outputId": "14fbede6-db6f-4ca9-abe4-1e589f27c84c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#importing tensorflow\n",
        "from tensorflow.keras.layers import Dense,Input,Conv2D,MaxPool2D,Activation,Dropout,Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "import random as rn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F6ZA7SY5DGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9_XaHM-t9mP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install rarfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRn5CEYQps6f",
        "colab_type": "code",
        "outputId": "65f8bb7e-7f2f-41f0-a9d4-e9e9ee03122e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWNlaD4gBTg_",
        "colab_type": "code",
        "outputId": "5f8b6e5e-f8d5-4dba-cc4f-16409e16a3dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aNHP3mLpMKv",
        "colab_type": "code",
        "outputId": "4fb1e022-ee27-4521-dace-a884e663272b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "\n",
        "# define the name of the directory to be created\n",
        "path = \"/content/drive/My Drive/Colab Notebooks/TL/rvl\"\n",
        "\n",
        "try:\n",
        "    os.makedirs(path)\n",
        "except OSError:\n",
        "    print (\"Creation of the directory %s failed\" % path)\n",
        "else:\n",
        "    print (\"Successfully created the directory %s \" % path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully created the directory /content/drive/My Drive/Colab Notebooks/TL/rvl \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHjecnhhUd5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import rarfile\n",
        "def unrar(dpath,xpath):\n",
        "  for rar in os.listdir(dpath):\n",
        "    filepath = os.path.join(dpath, rar)\n",
        "    with rarfile.RarFile(filepath) as opened_rar:\n",
        "      for f in opened_rar.infolist():\n",
        "        print (f.filename, f.file_size)\n",
        "        opened_rar.extractall(xpath)\n",
        "\n",
        "unrar(\"/content/drive/My Drive/Colab Notebooks/TL/\",\"/content/drive/My Drive/Colab Notebooks/TL/rvl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CD0QuxMpleYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir_path = \"/content/drive/My Drive/Colab Notebooks/TL/rvl\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmAJEQQzl8T7",
        "colab_type": "code",
        "outputId": "62419a43-5aeb-4282-fb00-52f11b9dacbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "os.listdir(dir_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data_final', 'labels_final.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDSCPyfnzRxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "data = pandas.read_csv('/content/drive/My Drive/Colab Notebooks/TL/rvl/labels_final.csv') \n",
        "#y = data['label'].values\n",
        "#X = data.drop(['label'], axis=1)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test = train_test_split(data,test_size=0.33)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpu1MzgDuu1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test = train_test_split(data, test_size=0.33)\n",
        "X_train, X_cv = train_test_split(X_train,test_size=0.33)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-D_ty5Rr6uQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def append_ext(fn):\n",
        "    return str(fn)\n",
        "\n",
        "\n",
        "\n",
        "def append_ext_path(fn):\n",
        "    return \"/content/drive/My Drive/Colab Notebooks/TL/rvl/data_final/\"+fn\n",
        "\n",
        "X_train[\"path\"]=X_train[\"path\"].apply(append_ext_path)\n",
        "X_train[\"path\"]=X_train[\"path\"].apply(append_ext)\n",
        "X_train[\"label\"]=X_train[\"label\"].apply(append_ext)\n",
        "\n",
        "X_test[\"label\"]=X_test[\"label\"].apply(append_ext)\n",
        "X_test[\"path\"]=X_test[\"path\"].apply(append_ext_path)\n",
        "X_test[\"path\"]=X_test[\"path\"].apply(append_ext)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRWL6K_0s7yL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen=ImageDataGenerator(rescale=1./255.,validation_split=0.25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H59HYNW-tdwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train[\"path\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eg3uRSiSI6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F497-penzGhz",
        "colab_type": "code",
        "outputId": "16874417-1626-4b2c-b662-62388c2a5ccb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        " \n",
        "train_generator=datagen.flow_from_dataframe(\n",
        "dataframe=X_train,\n",
        "directory=None,\n",
        "x_col=\"path\",\n",
        "y_col=\"label\",\n",
        "subset=\"training\",\n",
        "batch_size=32,\n",
        "seed=10,\n",
        "shuffle=True,\n",
        "class_mode=\"categorical\",\n",
        "target_size=(156,256))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 16161 validated image filenames belonging to 16 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lk5eq3HZH_Hc",
        "colab_type": "code",
        "outputId": "f6c584cc-c99f-4450-90ef-eccc98058163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        " \n",
        "valid_generator=datagen.flow_from_dataframe(\n",
        "dataframe=X_train,\n",
        "directory=None,\n",
        "x_col=\"path\",\n",
        "y_col=\"label\",\n",
        "subset=\"validation\",\n",
        "batch_size=32,\n",
        "seed=10,\n",
        "shuffle=True,\n",
        "class_mode=\"categorical\",\n",
        "target_size=(156,256))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5386 validated image filenames belonging to 16 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOJfE5bgIaud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_datagen=ImageDataGenerator(rescale=1./255.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgWVJzDztNfk",
        "colab_type": "code",
        "outputId": "2fd06dc2-2b0f-40a3-dc60-c6502617e9ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        " \n",
        "test_generator=test_datagen.flow_from_dataframe(\n",
        "dataframe=X_test,\n",
        "directory=None,\n",
        "x_col=\"path\",\n",
        "y_col=\"label\",\n",
        "subset=\"training\",\n",
        "batch_size=32,\n",
        "seed=10,\n",
        "shuffle=True,\n",
        "class_mode=\"categorical\",\n",
        "target_size=(156,256))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 15840 validated image filenames belonging to 16 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTLFYzjZ5gW0",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZXpEZtJcAEu",
        "colab_type": "text"
      },
      "source": [
        "### Model-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EF12MYu1cAEy",
        "colab_type": "text"
      },
      "source": [
        "<pre>\n",
        "1. Use <a href='https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG16'>VGG-16</a> pretrained network without Fully Connected layers and initilize all the weights with Imagenet trained weights. \n",
        "2. After VGG-16 network without FC layers, add a new Conv block ( 1 Conv layer and 1 Maxpooling ), 2 FC layers and a output layer to classify 16 classes. You are free to choose any hyperparameters/parameters of conv block, FC layers, output layer. \n",
        "3. Final architecture will be <b>INPUT --> VGG-16 without Top layers(FC) --> Conv Layer --> Maxpool Layer --> 2 FC layers --> Output Layer</b>\n",
        "4. Train only new Conv block, FC layers, output layer. Don't train the VGG-16 network. \n",
        "\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuOXpioJGhOR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpoYqnVb8vs1",
        "colab_type": "code",
        "outputId": "fc1a7686-d765-4d66-af03-93f7de5f4105",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#input_layer = Input(shape=(156,256,3),name='Input_Layer')\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "#IMG_SHAPE = (156,256,3)\n",
        "\n",
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "base_model = InceptionV3(include_top=False,weights='imagenet')\n",
        "\n",
        "#feature_batch = base_model(image_batch)\n",
        "#print(feature_batch.shape)\n",
        "#base_model=keras.applications.inception_v3.InceptionV3(include_top=False, weights='imagenet') \n",
        "base_model.trainable = False\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "87916544/87910968 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hd8eslVenPwW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "con=Conv2D(32,kernel_size=[3,3],strides=(1,1),padding=\"valid\",activation=\"relu\")(base_model.output)\n",
        "global_average_layer = layers.GlobalAveragePooling2D()(con)\n",
        "\n",
        "r1=Dense(1024, activation='relu')(global_average_layer)\n",
        "r2=Dense(1024, activation='relu')(r1)\n",
        "output = Dense(16,activation='softmax')(r2)\n",
        "model = Model(inputs=base_model.input,outputs=output)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ysn6ZT_r7MuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCZ_rWQlH9Tz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "model.compile(optimizer=Adam(lr=0.01),loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzcKnp21IsyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
        "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
        "model.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=10\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWMR5h-Q14Q5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBGWfJE5JM61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De0UlsaOcAE1",
        "colab_type": "text"
      },
      "source": [
        "### Model-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNXN3EXFcAE5",
        "colab_type": "text"
      },
      "source": [
        "<pre>\n",
        "1. Use <a href='https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG16'>VGG-16</a> pretrained network without Fully Connected layers and initilize all the weights with Imagenet trained weights.\n",
        "2. After VGG-16 network without FC layers, don't use FC layers, use conv layers only as Fully connected layer. any FC layer can be converted to a CONV layer. \n",
        "This conversion will reduce the No of Trainable parameters in FC layers.\n",
        " For example, an FC layer with K=4096 that is looking at some input volume of size 7×7×512 can be equivalently expressed as a CONV layer with F=7,P=0,S=1,K=4096. \n",
        " In other words, we are setting the filter size to be exactly the size of the input volume, and hence the output will simply be 1×1×4096 since only a single depth column “fits” across the input volume, giving identical result as the initial FC layer. \n",
        " You can refer <a href='http://cs231n.github.io/convolutional-networks/#convert'>this</a> link to better understanding of using Conv layer in place of fully connected layers.\n",
        "3. Final architecture will be VGG-16 without FC layers(without top), 2 Conv layers identical to FC layers, 1 output layer for 16 class classification. <b>INPUT --> VGG-16 without Top layers(FC) --> 2 Conv Layers identical to FC --> Output Layer</b>\n",
        "3. Train only last 2 Conv layers identical to FC layers, 1 output layer. Don't train the VGG-16 network. \n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSV2qdjE2qSN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e8jFDVRJ2qmJ",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JT0qsRBa3YjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications import VGG16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5H8f6zFFu4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(1):\n",
        "  model.layers.pop(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l3eIPpMv2qmW",
        "colab": {}
      },
      "source": [
        "input_layer = Input(shape=(156,156,3),name='Input_Layer')\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "\n",
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "base_model_new = VGG16(include_top=False,weights='imagenet')(input_layer)\n",
        "\n",
        "#feature_batch = base_model(image_batch)\n",
        "#print(feature_batch.shape)\n",
        "#base_model=keras.applications.inception_v3.InceptionV3(include_top=False, weights='imagenet') \n",
        "base_model_new.trainable = False\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSE6XDna_4eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_1=Conv2D(512,kernel_size=[1,1],strides=(1,1),padding=\"valid\",activation=\"relu\")(base_model_new)\n",
        "conv_2=Conv2D(512,kernel_size=[1,1],strides=(1,1),padding=\"valid\",activation=\"relu\")(conv_1)\n",
        "output = Dense(16,activation='softmax')(conv_2)\n",
        "model_new = Model(inputs=input_layer,outputs=output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtXm6st0PJfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vnWrzaQHPJyJ",
        "outputId": "e5ff16b7-35e7-42e9-ae60-7971afd7656d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fdHcgPLYPJyW",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "model_new.compile(optimizer=Adam(lr=0.01),loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3jD0OcsGPJyb",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
        "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
        "model_new.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fORZoFvFXeg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KTVxFMiAXbhk"
      },
      "source": [
        "### Model-3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GM6wzN3yXbhx"
      },
      "source": [
        "<pre>\n",
        "1. Use same network as Model-2 '<b>INPUT --> VGG-16 without Top layers(FC) --> 2 Conv Layers identical to FC --> Output Layer</b>' and train only Last 6 Layers of VGG-16 network, 2 Conv layers identical to FC layers, 1 output layer.\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miKsEZVUj9PL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CQRMJCssj9m6",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9jAIuF8Sj9nF",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications import VGG16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VwTJmQXaj9nJ",
        "colab": {}
      },
      "source": [
        "input_layer = Input(shape=(156,156,3),name='Input_Layer')\n",
        "from tensorflow.keras.applications import VGG16\n",
        "base_model_new3 = VGG16(include_top=False,weights='imagenet')\n",
        "for layer in base_model_new3.layers[:13]:\n",
        "    layer.trainable = False\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcttWqEndRiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in base_model_new.layers:\n",
        "    print(layer, layer.trainable)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWG-ArB9kHFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_1=Conv2D(512,kernel_size=[1,1],strides=(1,1),padding=\"valid\",activation=\"relu\")(base_model_new3)\n",
        "conv_2=Conv2D(512,kernel_size=[1,1],strides=(1,1),padding=\"valid\",activation=\"relu\")(conv_1)\n",
        "output = Dense(16,activation='softmax')(conv_2)\n",
        "model_new3 = Model(inputs=input_layer,outputs=output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1wpaDC9kTaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e5ff16b7-35e7-42e9-ae60-7971afd7656d",
        "id": "m4m8IiZakTqX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w73AQiT0kTqb",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "model_new3.compile(optimizer=Adam(lr=0.01),loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q-tPScadkTqf",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
        "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
        "model_new3.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}